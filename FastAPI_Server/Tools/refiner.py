from typing import Dict, Any
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.tools import tool
from dotenv import load_dotenv
from typing import List, Union
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, BaseMessage


load_dotenv(override=True)


@tool
def ContentRefiner(
    query: str,
    dependency_context: str = "",
    message_history: List[Union[AIMessage, HumanMessage]] = [],
) -> str:
    """
    The ContentRefiner tool takes a piece of text generated by previous tools (or extracted from the conversation history or memory)
    and refines it according to the userâ€™s request. Typical refinements include summarization, making the text more concise,
    expanding, rephrasing, adding professional polish, or humanizing tone, as suitable for finance, business, or general user needs.
    """
    try:

        def format_history(history: List[BaseMessage]) -> str:
            """Format message history into a string for model input."""
            formatted = ""
            for msg in history[-10:]:
                role = "User" if isinstance(msg, HumanMessage) else "Assistant"
                formatted += f"{role}: {msg.content}\n"
            return formatted.strip()

        history_str = format_history(message_history)
        # Step 1: Use LLM to intelligently formulate the search query
        structured_prompt = f"""
        Original User Query:
        {query}

        --- Dependency Context ---
        {dependency_context}

        --- Prior History ---
        {history_str}
        """
        llm = ChatGoogleGenerativeAI(
            model="gemini-2.0-flash",
            temperature=0,
        )
        system_prompt = """You are a Content Refinement AI with advanced capabilities in:
            Summarizing and distilling complex information

            Enhancing clarity, conciseness, and readability

            Optimizing output for a professional and SEO-friendly tone

            Humanizing AI-generated content for natural engagement

            Expanding or elaborating on material upon request

            Your task:
            Refine the content provided according to the user's instructions and ensure the output meets the intended style, tone, and purpose.

            Additionally:
            When refining, always take into account the following, if available:

            The current user query and its specific requirements

            Relevant conversation history for context and flow continuity

            Outputs from prior dependencies or agent steps that may inform or influence content refinement

            By integrating these elements, ensure that the response is coherent with ongoing discourse, utilizes prior reasoning or findings, and addresses the user's latest needs with maximum relevance and expertise.
            """
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": structured_prompt},
        ]
        response = llm.invoke(messages)
        result = response.content
    except Exception as e:
        print(f"Error in ContentRefiner: {e}")
    return result
